{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 3 : Use homemade dataset \n",
    "\n",
    "With this example, we dive deeper into the potential of the library, and run a scenario on a new dataset, that we will implement "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1 - Prerequisites\n",
    "\n",
    "In order to run this example, you'll need to:\n",
    "\n",
    "* use python 3.7 +\n",
    "* install requirements from the requirements.txt file\n",
    "* install this package https://test.pypi.org/project/mplc/\n",
    "\n",
    "If you did not follow our firsts tutorials, it is highly recommended to [take a look at it !](https://github.com/SubstraFoundation/distributed-learning-contributivity/tree/master/notebooks/examples/) \n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install mplc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2 - Context \n",
    "\n",
    "In collaborative data science projects partners sometimes need to train a model on multiple datasets, contributed by different data providing partners. In such cases the partners might have to measure how much each dataset involved contributed to the performance of the model. This is useful for example as a basis to agree on how to share the reward of the ML challenge or the future revenues derived from the predictive model, or to detect possible corrupted datasets or partners not playing by the rules. The library explores this question and the opportunity to implement some mechanisms helping partners in such scenarios to measure each dataset's *contributivity* (as *contribution to the performance of the model*).\n",
    "\n",
    "In the first tutorial, you learnt how to parametrize and run a scenario.\n",
    "In the second tutorial, you discovered how to add one of the contributivity measurement implemented to your scenario run.\n",
    "And in this tutorial, we are going to use our own dataset.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjxjesO3fyLN"
   },
   "source": [
    "### The dataset : Sentiment140\n",
    "We are going to use a subset of the [sentiment140](http://help.sentiment140.com/for-students) dataset and try to \n",
    "classified short film review, between positive sentiments and negative sentiments for movies. \n",
    "\n",
    "*The whole machine learning process is inspired from this [article](https://medium.com/@alyafey22/sentiment-classification-from-keras-to-the-browser-7eda0d87cdc6)*\n",
    "Please note that the library provided a really easy way to adapt a single partner, common machine learning use case with tensorflow, to a multipartner case, with contributivity measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "LDhMiOgNfyLO",
    "outputId": "24d31bb5-ea34-4625-c292-a9704c60e0c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Embedding\n",
    "\n",
    "from mplc.dataset import Dataset\n",
    "from mplc.scenario import Scenario\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n17Q_qx6fyLR"
   },
   "source": [
    "## 3 - Generation, and preparation of the dataset\n",
    " \n",
    "The scenario object needs a dataset object to run. In the previous tutorials, we indicate which one to generate automatically by passing a name of a pre-implemented dataset to the scenario constructor. \n",
    "Here, we will create this dataset object and pass it to the scenario constructor. \n",
    "\n",
    "The dataset needs few arguments. \n",
    "### Dataset generator :\n",
    "\n",
    "The structure of the dataset generator is represented below:\n",
    "\n",
    "```python\n",
    "dataset = Dataset(\n",
    "    \"name\",\n",
    "    x_train,\n",
    "    x_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    input_shape,\n",
    "    num_classes,                   \n",
    "    generate_new_model_for_dataset  # See below\n",
    "    train_val_split_global,         # See below\n",
    "    train_test_split_local,         # See below\n",
    "    train_val_split_local           # See below\n",
    ")\n",
    "```\n",
    "#### Data labels\n",
    "The data labels can take whatever shape you need, with only one condition. \n",
    "The labels need to be convertible into string format, and with respect to the condition that if label1 is equal to label2 (\n",
    "reciprocally different from), therefore str(label1) must be equal to str(label2) (reciprocally different from)\n",
    "#### Model generator\n",
    "This function provides the model use, which will be trained by the scenario object. \n",
    "Note: It is mandatory to have loss and accuracy as metrics for your model.\n",
    "\n",
    "#### Train/validation/test splits\n",
    "\n",
    "The dataset object must be provided some separated train and test sets (referred to as global train set and global test set).\n",
    "The global train set is then further split into a global train set and a global validation set, by the function `train_val_split_global`. Please denote that if this function is not provided, the sklearn's train_test_split function will be called by default, and 10% of the training set will be use as validation set. \n",
    "In the multi-partner learning computations, the global validation set is used for early stopping and the global test set is used for performance evaluation.\n",
    "The global train set is then split amongst partners (according to the scenario configuration) to populate the partner's local datasets.\n",
    "For each partner, the local dataset will be split into separated train, validation and test sets, using the `train_test_split_local` and `train_val_split_local` functions.\n",
    "These are not mandatory, by default the local dataset will not be split. \n",
    "Denote that currently, the local validation and test set are not used, but they are available for further developments of multi-partner learning and contributivity measurement approaches.\n",
    "\n",
    "### Dataset construction\n",
    "Now that we know all of that, we can create our dataset.\n",
    "#### Download and unzip data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "_7RrpjRnfyLS",
    "outputId": "5fdfed8b-c223-4742-f4e6-0fc86108de7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 77.5M  100 77.5M    0     0  15.0M      0  0:00:05  0:00:05 --:--:-- 15.9M\n",
      "Archive:  trainingandtestdata.zip\n",
      "  inflating: testdata.manual.2009.06.14.csv  \n",
      "  inflating: training.1600000.processed.noemoticon.csv  \n"
     ]
    }
   ],
   "source": [
    "!curl https://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip --output trainingandtestdata.zip\n",
    "!unzip trainingandtestdata.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qf36Veh3fyLU"
   },
   "source": [
    "#### Define preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TGfN4EvfyLU",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def process(txt):\n",
    "    out = re.sub(r'[^a-zA-Z0-9\\s]', '', txt)\n",
    "    out = out.split()\n",
    "    out = [word.lower() for word in out]\n",
    "    return out\n",
    "\n",
    "def getMax(data):\n",
    "    max_tokens = 0 \n",
    "    for txt in data:\n",
    "        if max_tokens < len(txt.split()):\n",
    "            max_tokens = len(txt.split())\n",
    "    return max_tokens\n",
    "\n",
    "\n",
    "def tokenize(thresh = 5):\n",
    "    count  = dict()\n",
    "    idx = 1\n",
    "    word_index = dict()\n",
    "    for txt in x:\n",
    "        words = process(txt)\n",
    "        for word in words:\n",
    "            if word in count.keys():\n",
    "                count[word] += 1\n",
    "            else:\n",
    "                count[word]  = 1\n",
    "    most_counts = [word for word in count.keys() if count[word]>=thresh]\n",
    "    for word in most_counts:\n",
    "        word_index[word] = idx\n",
    "        idx+=1\n",
    "    return word_index\n",
    "\n",
    "\n",
    "def create_sequences(data):\n",
    "    tokens = []\n",
    "    for txt in data:\n",
    "        words = process(txt)\n",
    "        seq = [0] * max_tokens\n",
    "        i = 0 \n",
    "        for word in words:\n",
    "            start = max_tokens-len(words)\n",
    "            if word.lower() in word_index.keys():\n",
    "                seq[i+start] = word_index[word]\n",
    "            i+=1\n",
    "        tokens.append(seq)        \n",
    "    return np.array(tokens)\n",
    "\n",
    "def preprocess_dataset_labels(label):\n",
    "    label = np.array([e/4 for e in label])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngCAllxOfyLW"
   },
   "source": [
    "#### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T4u72Yt9fyLX"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", encoding = \"raw_unicode_escape\", header=None)\n",
    "df_test = pd.read_csv(\"testdata.manual.2009.06.14.csv\", encoding = \"raw_unicode_escape\",  header=None)\n",
    "\n",
    "df_train.columns = [\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "df_test.columns = [\"polarity\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "\n",
    "# We keep only a fraction of the whole dataset\n",
    "\n",
    "df_train = df_train.sample(frac = 0.1)\n",
    "\n",
    "x = df_train[\"text\"]\n",
    "y = df_train[\"polarity\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "BMnzI5BdfyLZ",
    "outputId": "a05a046d-415e-4249-9cb3-4f90744f1b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the dictionary  15174\n",
      "max token  39\n",
      "num classes 2\n"
     ]
    }
   ],
   "source": [
    "max_tokens = getMax(x)\n",
    "\n",
    "num_words = None\n",
    "word_index = tokenize()\n",
    "num_words = len(word_index)\n",
    "\n",
    "x = create_sequences(x)\n",
    "y = preprocess_dataset_labels(y)\n",
    "\n",
    "input_shape = max_tokens\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "\n",
    "print('length of the dictionary ',len(word_index))\n",
    "print('max token ', max_tokens) \n",
    "print('num classes', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLB_qr24fyLb"
   },
   "outputs": [],
   "source": [
    "(x_train, x_test) = train_test_split(x, shuffle = False)\n",
    "(y_train, y_test) = train_test_split(y, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdrjGXIJfyLg"
   },
   "source": [
    "#### Create Model generator\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fgT4A72fyLg"
   },
   "outputs": [],
   "source": [
    "def generate_new_model_for_dataset():\n",
    "    model = Sequential()\n",
    "    embedding_size = 8\n",
    "    model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))\n",
    "\n",
    "    model.add(GRU(units=16, name = \"gru_1\",return_sequences=True))\n",
    "    model.add(GRU(units=8, name = \"gru_2\" ,return_sequences=True))\n",
    "    model.add(GRU(units=4, name= \"gru_3\"))\n",
    "    model.add(Dense(1, activation='sigmoid',name=\"dense_1\"))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "And eventually, generate our object !"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gh0VIIzhfyLj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_dataset = Dataset(\n",
    "    \"my_dataset\",\n",
    "    x_train,\n",
    "    x_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    input_shape,\n",
    "    num_classes,\n",
    "    generate_new_model_for_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwRIBrVWfyLe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4 - Create the custom scenario\n",
    "The dataset can be passed to the scenario, through the `dataset` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "Vo2N04qmfyLe",
    "outputId": "26815c46-5d52-471d-d6a5-08a7cdd4f5ba",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 11:23:59.182 | DEBUG    | subtest.scenario:__init__:58 - Dataset selected: mnist\n",
      "2020-08-26 11:23:59.186 | DEBUG    | subtest.scenario:__init__:93 - Computation use the full dataset for scenario #1\n",
      "2020-08-26 11:23:59.332 | INFO     | subtest.scenario:__init__:282 - ### Description of data scenario configured:\n",
      "2020-08-26 11:23:59.333 | INFO     | subtest.scenario:__init__:283 -    Number of partners defined: 3\n",
      "2020-08-26 11:23:59.334 | INFO     | subtest.scenario:__init__:284 -    Data distribution scenario chosen: random\n",
      "2020-08-26 11:23:59.337 | INFO     | subtest.scenario:__init__:285 -    Multi-partner learning approach: fedavg\n",
      "2020-08-26 11:23:59.339 | INFO     | subtest.scenario:__init__:286 -    Weighting option: uniform\n",
      "2020-08-26 11:23:59.341 | INFO     | subtest.scenario:__init__:287 -    Iterations parameters: 10 epochs > 3 mini-batches > 8 gradient updates per pass\n",
      "2020-08-26 11:23:59.343 | INFO     | subtest.scenario:__init__:293 - ### Data loaded: mnist\n",
      "2020-08-26 11:23:59.344 | INFO     | subtest.scenario:__init__:294 -    48000 train data with 48000 labels\n",
      "2020-08-26 11:23:59.346 | INFO     | subtest.scenario:__init__:295 -    12000 val data with 12000 labels\n",
      "2020-08-26 11:23:59.348 | INFO     | subtest.scenario:__init__:296 -    10000 test data with 10000 labels\n"
     ]
    }
   ],
   "source": [
    "my_scenario = Scenario(partners_count=3,\n",
    "                           amounts_per_partner=[0.2, 0.5, 0.3],\n",
    "                           epoch_count=10,\n",
    "                           minibatch_count=3,\n",
    "                           dataset=my_dataset)\n",
    "# Every other parameter will be set to its default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_qnFUVwCfyLp",
    "outputId": "c489b38f-c947-45d7-dce6-32430da33e1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 11:23:59.507 | INFO     | subtest.scenario:split_data:537 - ### Splitting data among partners:\n",
      "2020-08-26 11:23:59.611 | INFO     | subtest.scenario:split_data:538 -    Simple split performed.\n",
      "2020-08-26 11:23:59.614 | INFO     | subtest.scenario:split_data:539 -    Nb of samples split amongst partners: 77760\n",
      "2020-08-26 11:23:59.615 | INFO     | subtest.scenario:split_data:541 -    Partner #0: 15552 samples with labels [0, 4]\n",
      "2020-08-26 11:23:59.617 | INFO     | subtest.scenario:split_data:541 -    Partner #1: 38880 samples with labels [0, 4]\n",
      "2020-08-26 11:23:59.618 | INFO     | subtest.scenario:split_data:541 -    Partner #2: 23328 samples with labels [0, 4]\n",
      "2020-08-26 11:23:59.900 | DEBUG    | subtest.scenario:compute_batch_sizes:585 -    Compute batch sizes, partner #0: 648\n",
      "2020-08-26 11:23:59.901 | DEBUG    | subtest.scenario:compute_batch_sizes:585 -    Compute batch sizes, partner #1: 1620\n",
      "2020-08-26 11:23:59.901 | DEBUG    | subtest.scenario:compute_batch_sizes:585 -    Compute batch sizes, partner #2: 972\n",
      "2020-08-26 11:23:59.903 | DEBUG    | subtest.scenario:preprocess_scenarios_data:590 - ## Pre-processing datasets of the scenario for keras CNN:\n",
      "2020-08-26 11:23:59.925 | DEBUG    | subtest.scenario:preprocess_scenarios_data:594 -    Central early stopping validation set: done.\n",
      "2020-08-26 11:23:59.949 | DEBUG    | subtest.scenario:preprocess_scenarios_data:596 -    Central testset: done.\n",
      "2020-08-26 11:23:59.964 | DEBUG    | subtest.scenario:preprocess_scenarios_data:618 -    Partner #0: done.\n",
      "2020-08-26 11:23:59.988 | DEBUG    | subtest.scenario:preprocess_scenarios_data:618 -    Partner #1: done.\n",
      "2020-08-26 11:24:00.004 | DEBUG    | subtest.scenario:preprocess_scenarios_data:618 -    Partner #2: done.\n",
      "2020-08-26 11:24:00.005 | DEBUG    | subtest.multi_partner_learning:__init__:69 - MultiPartnerLearning object instantiated.\n",
      "2020-08-26 11:24:00.006 | INFO     | subtest.multi_partner_learning:compute_test_score:135 - ## Training and evaluating model on partners with ids: ['#0', '#1', '#2']\n",
      "2020-08-26 11:24:00.036 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:24:00.037 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:268 - (fedavg) Very first minibatch of epoch n°0, init new models for each partner\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "2020-08-26 11:24:14.254 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 00/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.52\n",
      "2020-08-26 11:24:21.525 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 00/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.5\n",
      "2020-08-26 11:24:29.141 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 00/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.55\n",
      "2020-08-26 11:24:29.154 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:24:29.155 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:24:29.161 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°0, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:24:40.409 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 00/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.5\n",
      "2020-08-26 11:24:47.794 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 00/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.53\n",
      "2020-08-26 11:24:55.131 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 00/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.56\n",
      "2020-08-26 11:24:55.140 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:24:55.141 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:24:55.141 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°0, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:25:05.900 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 00/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.62\n",
      "2020-08-26 11:25:13.067 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 00/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.5\n",
      "2020-08-26 11:25:20.973 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 00/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.55\n",
      "2020-08-26 11:25:20.983 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:25:23.964 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.692', '0.530']\n",
      "2020-08-26 11:25:23.966 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:25:23.969 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:25:24.005 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:25:24.006 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°1, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:25:35.291 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 01/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.63\n",
      "2020-08-26 11:25:42.854 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 01/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.52\n",
      "2020-08-26 11:25:50.355 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 01/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.63\n",
      "2020-08-26 11:25:50.364 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:25:50.366 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:25:50.368 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°1, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:26:01.233 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 01/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.63\n",
      "2020-08-26 11:26:08.070 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 01/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.6\n",
      "2020-08-26 11:26:15.925 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 01/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.57\n",
      "2020-08-26 11:26:15.932 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:26:15.933 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:26:15.934 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°1, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:26:27.536 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 01/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.64\n",
      "2020-08-26 11:26:35.006 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 01/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.62\n",
      "2020-08-26 11:26:42.484 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 01/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.63\n",
      "2020-08-26 11:26:42.492 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:26:45.693 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.684', '0.639']\n",
      "2020-08-26 11:26:45.694 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:26:45.697 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:26:45.730 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:26:45.731 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°2, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:26:58.511 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 02/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.63\n",
      "2020-08-26 11:27:05.522 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 02/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.64\n",
      "2020-08-26 11:27:12.993 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 02/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.63\n",
      "2020-08-26 11:27:13.001 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:27:13.002 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:27:13.005 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°2, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:27:24.759 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 02/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.64\n",
      "2020-08-26 11:27:32.152 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 02/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.64\n",
      "2020-08-26 11:27:39.817 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 02/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.64\n",
      "2020-08-26 11:27:39.827 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:27:39.828 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:27:39.833 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°2, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:27:50.899 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 02/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.64\n",
      "2020-08-26 11:27:58.862 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 02/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.64\n",
      "2020-08-26 11:28:06.795 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 02/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.63\n",
      "2020-08-26 11:28:06.806 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:28:09.803 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.663', '0.635']\n",
      "2020-08-26 11:28:09.804 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:28:09.805 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:28:09.846 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:28:09.848 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°3, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:28:20.955 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 03/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.65\n",
      "2020-08-26 11:28:27.804 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 03/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.64\n",
      "2020-08-26 11:28:35.137 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 03/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.65\n",
      "2020-08-26 11:28:35.144 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:28:35.145 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:28:35.147 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°3, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:28:47.561 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 03/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.66\n",
      "2020-08-26 11:28:54.748 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 03/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.66\n",
      "2020-08-26 11:29:02.250 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 03/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.66\n",
      "2020-08-26 11:29:02.264 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:29:02.264 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:29:02.271 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°3, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:29:14.082 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 03/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.66\n",
      "2020-08-26 11:29:21.943 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 03/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.67\n",
      "2020-08-26 11:29:29.429 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 03/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.66\n",
      "2020-08-26 11:29:29.438 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:29:32.672 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.627', '0.667']\n",
      "2020-08-26 11:29:32.674 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:29:32.677 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:29:32.719 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:29:32.721 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°4, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:29:43.810 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 04/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.68\n",
      "2020-08-26 11:29:52.329 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 04/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.68\n",
      "2020-08-26 11:29:59.951 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 04/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.68\n",
      "2020-08-26 11:29:59.960 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:29:59.961 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:29:59.967 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°4, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:30:11.129 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 04/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.7\n",
      "2020-08-26 11:30:18.428 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 04/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.7\n",
      "2020-08-26 11:30:26.617 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 04/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.7\n",
      "2020-08-26 11:30:26.627 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:30:26.628 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:30:26.633 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°4, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:30:38.343 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 04/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.71\n",
      "2020-08-26 11:30:45.777 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 04/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.71\n",
      "2020-08-26 11:30:53.104 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 04/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.71\n",
      "2020-08-26 11:30:53.111 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:30:56.114 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.581', '0.713']\n",
      "2020-08-26 11:30:56.115 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:30:56.118 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:30:56.147 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:30:56.149 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°5, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:31:08.601 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 05/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.72\n",
      "2020-08-26 11:31:16.139 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 05/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.72\n",
      "2020-08-26 11:31:23.580 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 05/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.72\n",
      "2020-08-26 11:31:23.590 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:31:23.591 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:31:23.592 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°5, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:31:35.477 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 05/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.72\n",
      "2020-08-26 11:31:42.928 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 05/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.73\n",
      "2020-08-26 11:31:50.370 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 05/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.73\n",
      "2020-08-26 11:31:50.378 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:31:50.379 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:31:50.380 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°5, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:32:01.754 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 05/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.74\n",
      "2020-08-26 11:32:09.973 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 05/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.73\n",
      "2020-08-26 11:32:17.883 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 05/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.73\n",
      "2020-08-26 11:32:17.893 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:32:20.917 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.554', '0.734']\n",
      "2020-08-26 11:32:20.919 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:32:20.921 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:32:20.947 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:32:20.948 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°6, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:32:32.370 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 06/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.73\n",
      "2020-08-26 11:32:39.385 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 06/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.74\n",
      "2020-08-26 11:32:46.811 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 06/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.74\n",
      "2020-08-26 11:32:46.821 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:32:46.822 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:32:46.826 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°6, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:32:59.571 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 06/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.74\n",
      "2020-08-26 11:33:06.911 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 06/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.75\n",
      "2020-08-26 11:33:14.464 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 06/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.74\n",
      "2020-08-26 11:33:14.474 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:33:14.475 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:33:14.480 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°6, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:33:26.115 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 06/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.75\n",
      "2020-08-26 11:33:33.300 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 06/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.74\n",
      "2020-08-26 11:33:40.801 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 06/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.75\n",
      "2020-08-26 11:33:40.811 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:33:43.737 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.537', '0.747']\n",
      "2020-08-26 11:33:43.739 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:33:43.744 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:33:43.770 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:33:43.772 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°7, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:33:54.757 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 07/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.74\n",
      "2020-08-26 11:34:03.836 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 07/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.75\n",
      "2020-08-26 11:34:11.717 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 07/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.75\n",
      "2020-08-26 11:34:11.723 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:34:11.725 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:34:11.726 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°7, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:34:22.887 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 07/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.75\n",
      "2020-08-26 11:34:29.925 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 07/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.75\n",
      "2020-08-26 11:34:38.090 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 07/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.75\n",
      "2020-08-26 11:34:38.098 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:34:38.099 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:34:38.104 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°7, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:34:50.030 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 07/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.75\n",
      "2020-08-26 11:34:57.096 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 07/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.75\n",
      "2020-08-26 11:35:05.059 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 07/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.75\n",
      "2020-08-26 11:35:05.065 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:35:07.951 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.526', '0.748']\n",
      "2020-08-26 11:35:07.952 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:35:07.955 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:35:07.982 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:35:07.983 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°8, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:35:20.855 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 08/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.75\n",
      "2020-08-26 11:35:28.009 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 08/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.76\n",
      "2020-08-26 11:35:35.433 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 08/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.75\n",
      "2020-08-26 11:35:35.442 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:35:35.443 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:35:35.445 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°8, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:35:47.152 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 08/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.76\n",
      "2020-08-26 11:35:54.378 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 08/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.76\n",
      "2020-08-26 11:36:01.757 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 08/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.76\n",
      "2020-08-26 11:36:01.765 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:36:01.766 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:36:01.767 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°8, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:36:13.596 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 08/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.76\n",
      "2020-08-26 11:36:20.665 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 08/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.76\n",
      "2020-08-26 11:36:28.103 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 08/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.76\n",
      "2020-08-26 11:36:28.110 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:36:31.078 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.513', '0.763']\n",
      "2020-08-26 11:36:31.080 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:36:31.082 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:36:31.107 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:36:31.108 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°0 of epoch n°9, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:36:42.390 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 09/09 > Minibatch 00/02 > Partner id #0 (0/2) > val_acc: 0.76\n",
      "2020-08-26 11:36:49.433 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 09/09 > Minibatch 00/02 > Partner id #1 (1/2) > val_acc: 0.76\n",
      "2020-08-26 11:36:58.254 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 09/09 > Minibatch 00/02 > Partner id #2 (2/2) > val_acc: 0.76\n",
      "2020-08-26 11:36:58.265 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:36:58.266 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:36:58.271 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°1 of epoch n°9, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:37:09.382 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 09/09 > Minibatch 01/02 > Partner id #0 (0/2) > val_acc: 0.77\n",
      "2020-08-26 11:37:16.676 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 09/09 > Minibatch 01/02 > Partner id #1 (1/2) > val_acc: 0.77\n",
      "2020-08-26 11:37:24.897 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 09/09 > Minibatch 01/02 > Partner id #2 (2/2) > val_acc: 0.77\n",
      "2020-08-26 11:37:24.906 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:37:24.909 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:259 - Start new fedavg collaborative round ...\n",
      "2020-08-26 11:37:24.910 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:271 - (fedavg) Minibatch n°2 of epoch n°9, init aggregated model for each partner with models from previous round\n",
      "2020-08-26 11:37:36.259 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 09/09 > Minibatch 02/02 > Partner id #0 (0/2) > val_acc: 0.77\n",
      "2020-08-26 11:37:44.070 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 09/09 > Minibatch 02/02 > Partner id #1 (1/2) > val_acc: 0.77\n",
      "2020-08-26 11:37:51.687 | DEBUG    | subtest.multi_partner_learning:log_collaborative_round_partner_result:513 - Epoch 09/09 > Minibatch 02/02 > Partner id #2 (2/2) > val_acc: 0.77\n",
      "2020-08-26 11:37:51.697 | DEBUG    | subtest.multi_partner_learning:compute_collaborative_round_fedavg:303 - End of fedavg collaborative round.\n",
      "2020-08-26 11:37:54.627 | INFO     | subtest.multi_partner_learning:compute_test_score:184 -    Model evaluation at the end of the epoch: ['0.506', '0.767']\n",
      "2020-08-26 11:37:54.628 | DEBUG    | subtest.multi_partner_learning:compute_test_score:187 -       Checking if early stopping criteria are met:\n",
      "2020-08-26 11:37:54.630 | DEBUG    | subtest.multi_partner_learning:compute_test_score:197 -          -> Early stopping criteria are not met, continuing with training.\n",
      "2020-08-26 11:37:54.634 | INFO     | subtest.multi_partner_learning:compute_test_score:200 - ### Evaluating model on test data:\n",
      "2020-08-26 11:37:58.581 | INFO     | subtest.multi_partner_learning:compute_test_score:203 -    Model metrics names: ['loss', 'accuracy']\n",
      "2020-08-26 11:37:58.582 | INFO     | subtest.multi_partner_learning:compute_test_score:204 -    Model metrics values: ['0.507', '0.767']\n",
      "2020-08-26 11:37:58.902 | INFO     | subtest.multi_partner_learning:compute_test_score:212 - Training and evaluation on multiple partners: done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_scenario.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyMh53L-fyLr"
   },
   "source": [
    "## 5 - Accuracy score between each partner and comparison with aggregated model performance\n",
    "\n",
    "Like in the first tutorial, we take a look at the scores, local and global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "En66AhKxfyLs",
    "outputId": "3a4b250e-864b-4697-ff77-b87ba4a300d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.7673\n",
      "Name: mpl_test_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "scores = my_scenario.mpl.score_matrix_per_partner.mean(axis = 1)\n",
    "score_collective = my_scenario.mpl.score_matrix_collective_models.mean(axis=1)\n",
    "\n",
    "scores_df = pd.DataFrame({\n",
    "    f'partner {i}':scores[:,i] for i in range(my_scenario.partners_count) })\n",
    "scores_df['collective model'] = score_collective\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Z5uyZkcfyLu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can plot the evolution of the accuracy through the epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-2c87b6509e0f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0msns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0msns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrelplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscores_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"line\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'scores_df' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'scores_df' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "ax = sns.relplot(data = scores_df, kind=\"line\")\n",
    "ax.set(xlabel='epochs', ylabel='accuracy', title='Accuracy evolution through the epochs')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "# That's it !\n",
    "\n",
    "Now you can explore our other tutorials for a better snapshot of what can be done with our library!\n",
    "\n",
    "This work is collaborative, enthusiasts are welcome to comment open issues and PRs or open new ones.\n",
    "\n",
    "Should you be interested in this open effort and would like to share any question, suggestion or input, you can use the following channels:\n",
    "\n",
    "- This Github repository (issues or PRs)\n",
    "- Substra Foundation's [Slack workspace](https://substra-workspace.slack.com/join/shared_invite/zt-cpyedcab-FHYgpy08efKJ2FCadE2yCA), channel `#workgroup-mpl-contributivity`\n",
    "- Email: hello@substra.org\n",
    "- Come meet with us at La Paillasse (Paris, France), Le Palace (Nantes, France) or Studio Iconosquare (Limoges, France)\n",
    "\n",
    " ![logo Substra Foundation](./img/substra_logo_couleur_rvb_w150px.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "2 _Sentiment140.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}